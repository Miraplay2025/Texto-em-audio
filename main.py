import os
import soundfile as sf
import whisper
import gradio as gr
from f5_tts.api import F5TTS # Usaremos a classe base que o sistema reconhece

# Inicializando a IA forÃ§ando o modelo E2 (Mais multilingue)
print("ğŸš€ Miraplay AI: Ativando motor E2-TTS...")
try:
    # Mudamos o model_type para 'e2' aqui dentro
    tts = F5TTS(model_type="e2") 
    print("âœ… Motor E2 carregado!")
except:
    # Caso a versÃ£o seja muito antiga e nÃ£o aceite o parÃ¢metro, ele usa o padrÃ£o
    tts = F5TTS()
    print("âœ… Motor F5 carregado (Modo Compatibilidade)")

modelo_transcritor = whisper.load_model("base")

def clonar_voz_miraplay(texto_para_gerar, audio_ref):
    try:
        if audio_ref is None:
            return None
        
        print(f"ğŸ§ Analisando Ã¡udio com Whisper...")
        # ForÃ§amos o Whisper a entender que o Ã¡udio de referÃªncia Ã© PT
        resultado = modelo_transcritor.transcribe(audio_ref, language="pt")
        texto_detectado = resultado["text"].strip()
        print(f"ğŸ“ Texto detectado: {texto_detectado}")

        output_file = "saida_miraplay.wav"

        # GeraÃ§Ã£o do Ã¡udio
        wav, sr, _ = tts.infer(
            gen_text=texto_para_gerar,
            ref_file=audio_ref,
            ref_text=texto_detectado
        )
        
        sf.write(output_file, wav, sr)
        print(f"âœ… Clonagem concluÃ­da!")
        return output_file

    except Exception as e:
        print(f"ğŸ’¥ Erro: {str(e)}")
        return None

app = gr.Interface(
    fn=clonar_voz_miraplay,
    inputs=[
        gr.Textbox(label="O que a IA deve falar (Use acentos: Ã¡, Ã©, Ã­, Ãµ)"),
        gr.Audio(type="filepath", label="Ãudio de ReferÃªncia (Voz da pessoa)")
    ],
    outputs=gr.Audio(label="Ãudio Final"),
    title="MIRAPLAY 2026 - MODO BRASIL",
    description="Sistema atualizado para evitar sotaque estrangeiro."
)

if __name__ == "__main__":
    app.launch(share=True, debug=True)
