import os
import soundfile as sf
import whisper
from f5_tts.api import F5TTS
import gradio as gr

# Carregando os modelos
print("ğŸš€ Miraplay AI: Ajustando para mÃºltiplos idiomas...")
tts = F5TTS()
modelo_transcritor = whisper.load_model("base")

def clonar_voz_miraplay(texto_para_gerar, audio_ref, idioma):
    try:
        if audio_ref is None:
            return None
        
        # 1. TranscriÃ§Ã£o automÃ¡tica com dica de idioma para o Whisper
        print(f"ğŸ§ Transcrevendo Ã¡udio em {idioma}...")
        # Traduzindo a escolha para o cÃ³digo que o Whisper entende
        lang_code = "pt" if idioma == "PortuguÃªs" else "en"
        
        resultado = modelo_transcritor.transcribe(audio_ref, language=lang_code)
        texto_detectado = resultado["text"].strip()
        print(f"ğŸ“ Texto da amostra: {texto_detectado}")

        output_file = "saida_miraplay.wav"

        # 2. InferÃªncia da IA
        # O F5-TTS usa o ref_text para captar a cadÃªncia do idioma escolhido
        wav, sr, _ = tts.infer(
            gen_text=texto_para_gerar,
            ref_file=audio_ref,
            ref_text=texto_detectado
        )
        
        sf.write(output_file, wav, sr)
        print(f"âœ… Clonagem em {idioma} concluÃ­da!")
        return output_file

    except Exception as e:
        print(f"ğŸ’¥ Erro: {str(e)}")
        return None

# Interface com SeleÃ§Ã£o de Idioma
app = gr.Interface(
    fn=clonar_voz_miraplay,
    inputs=[
        gr.Textbox(label="1. Texto que a IA vai falar"),
        gr.Audio(type="filepath", label="2. Ãudio de ReferÃªncia"),
        gr.Dropdown(
            choices=["PortuguÃªs", "InglÃªs"], 
            value="PortuguÃªs", 
            label="3. Selecione o Idioma"
        )
    ],
    outputs=gr.Audio(label="Resultado da Clonagem"),
    title="MIRAPLAY 2026 - MULTI-IDIOMAS",
    description="Agora vocÃª pode forÃ§ar a IA a falar no idioma correto selecionando acima."
)

if __name__ == "__main__":
    app.launch(share=True, debug=True)
